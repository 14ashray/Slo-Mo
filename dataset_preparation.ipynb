{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from joblib import Parallel, delayed\n",
    "from timeit import default_timer as timer\n",
    "from torchvision.transforms.functional import crop as crop_image\n",
    "from os.path import exists, join, basename, isdir\n",
    "from os import makedirs, remove, listdir, rmdir, rename\n",
    "from six.moves import urllib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch\n",
    "from torchvision.transforms import CenterCrop, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation\n",
    "import random\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE: int = 128\n",
    "RANDOM_TEMPORAL_ORDER_SWAP_PROB: float = 0.5\n",
    "MAX_TRAINING_SAMPLES: int = 500_000\n",
    "MAX_VALIDATION_SAMPLES: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    \n",
    "    dataset_dir = \"\"\n",
    "    workers = 0\n",
    "    json_path = join(dataset_dir, 'patches.json')\n",
    "    \n",
    "    davis_dir = \"\"\n",
    "    tuples = tuples_from_davis(davis_dir, res='480p')\n",
    "    \n",
    "\n",
    "    patches = extract_patches(tuples,max_per_frame=20,trials_per_tuple=30,flow_threshold=25.0,jumpcut_threshold=8e-3)\n",
    "    \n",
    "    random.shuffle(patches)\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(patches, f)\n",
    "        \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuples_from_davis(davis_dir, res='480p'):\n",
    "\n",
    "    subdir = join(davis_dir, \"JPEGImages/\" + res)\n",
    "\n",
    "    video_dirs = [join(subdir, x) for x in listdir(subdir)]\n",
    "    video_dirs = [x for x in video_dirs if isdir(x)]\n",
    "\n",
    "    tuples = []\n",
    "    for video_dir in video_dirs:\n",
    "\n",
    "        frame_paths = [join(video_dir, x) for x in listdir(video_dir)]\n",
    "        frame_paths = [x for x in frame_paths if is_image(x)]\n",
    "        frame_paths.sort()\n",
    "\n",
    "        for i in range(len(frame_paths) // 3):\n",
    "            x1, t, x2 = frame_paths[i * 3], frame_paths[i * 3 + 1], frame_paths[i * 3 + 2]\n",
    "            tuples.append((x1, t, x2))\n",
    "\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(tuples, max_per_frame=1, trials_per_tuple=100, flow_threshold=0.0,jumpcut_threshold=np.inf):\n",
    "\n",
    "    patch_h, patch_w = 150,150\n",
    "    n_tuples = len(tuples)\n",
    "    all_patches = []\n",
    "    jumpcuts = 0\n",
    "    flowfiltered = 0\n",
    "    total_iters = n_tuples * trials_per_tuple\n",
    "\n",
    "    pil_to_numpy = lambda x: np.array(x)[:, :, ::-1]\n",
    "\n",
    "    for tup_index in range(n_tuples):\n",
    "        tup = tuples[tup_index]\n",
    "\n",
    "        left, middle, right = (load_img(x) for x in tup)\n",
    "        img_w, img_h = left.size\n",
    "\n",
    "        left = pil_to_numpy(left)\n",
    "        middle = pil_to_numpy(middle)\n",
    "        right = pil_to_numpy(right)\n",
    "\n",
    "        selected_patches = []\n",
    "\n",
    "        for _ in range(trials_per_tuple):\n",
    "\n",
    "            i = random.randint(0, img_h - patch_h)\n",
    "            j = random.randint(0, img_w - patch_w)\n",
    "\n",
    "            left_patch = left[i:i + patch_h, j:j + patch_w, :]\n",
    "            right_patch = right[i:i + patch_h, j:j + patch_w, :]\n",
    "            middle_patch = middle[i:i + patch_h, j:j + patch_w, :]\n",
    "\n",
    "            if is_jumpcut(left_patch, middle_patch, jumpcut_threshold) or \\\n",
    "                    is_jumpcut(middle_patch, right_patch, jumpcut_threshold):\n",
    "                jumpcuts += 1\n",
    "                continue\n",
    "\n",
    "            avg_flow = simple_flow(left_patch, right_patch)\n",
    "            if random.random() > avg_flow / flow_threshold:\n",
    "                flowfiltered += 1\n",
    "                continue\n",
    "\n",
    "            selected_patches.append({\n",
    "                \"left_frame\": tup[0],\n",
    "                \"middle_frame\": tup[1],\n",
    "                \"right_frame\": tup[2],\n",
    "                \"patch_i\": i,\n",
    "                \"patch_j\": j,\n",
    "                \"avg_flow\": avg_flow\n",
    "            })\n",
    "\n",
    "        sorted(selected_patches, key=lambda x: x['avg_flow'], reverse=True)\n",
    "        all_patches += selected_patches[:max_per_frame]\n",
    "\n",
    "    print('===> Processed {} tuples, {} patches extracted, {} discarded as jumpcuts, {} filtered by flow'.format(\n",
    "        n_tuples, len(all_patches), 100.0 * jumpcuts / total_iters, 100.0 * flowfiltered / total_iters\n",
    "    ))\n",
    "\n",
    "    return all_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(file_path):\n",
    "    return any(file_path.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_jumpcut(frame1, frame2, threshold=np.inf):\n",
    "    pixels_per_channel = frame1.size / 3\n",
    "    hist = lambda x: np.histogram(x.reshape(-1), 8, (0, 255))[0] / pixels_per_channel\n",
    "    err = lambda a, b: ((hist(a) - hist(b)) ** 2).mean()\n",
    "\n",
    "    return err(frame1[:, :, 0], frame2[:, :, 0]) > threshold or \\\n",
    "           err(frame1[:, :, 1], frame2[:, :, 1]) > threshold or \\\n",
    "           err(frame1[:, :, 2], frame2[:, :, 2]) > threshold\n",
    "\n",
    "\n",
    "def simple_flow(frame1, frame2):\n",
    "    flow = cv.optflow.calcOpticalFlowSF(frame1, frame2, layers=3, averaging_block_size=2, max_flow=4)\n",
    "    n = np.sum(1 - np.isnan(flow), axis=(0, 1))\n",
    "    flow[np.isnan(flow)] = 0\n",
    "    return np.linalg.norm(np.sum(flow, axis=(0, 1)) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patch(patch):\n",
    "    paths = (patch['left_frame'], patch['middle_frame'], patch['right_frame'])\n",
    "    i, j = (patch['patch_i'], patch['patch_j'])\n",
    "    imgs = [load_img(x) for x in paths]\n",
    "    h, w = config.PATCH_SIZE\n",
    "    return tuple(crop_image(x, i, j, h, w) for x in imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_path):\n",
    "    return Image.open(file_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_to_numpy(x_pil):\n",
    "    return np.rollaxis(np.asarray(x_pil) / 255.0, 2)\n",
    "\n",
    "\n",
    "def pil_to_tensor(x_pil):\n",
    "    x_np = pil_to_numpy(x_pil)\n",
    "    return torch.from_numpy(x_np).float()\n",
    "\n",
    "\n",
    "def numpy_to_pil(x_np):\n",
    "    x_np = x_np.copy()\n",
    "    x_np *= 255.0\n",
    "    x_np = x_np.clip(0, 255)\n",
    "    x_np = np.rollaxis(x_np, 0, 3).astype(np.uint8)\n",
    "    return Image.fromarray(x_np, mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, patches):\n",
    "        super(PatchDataset, self).__init__()\n",
    "        self.patches = patches\n",
    "        self.crop = CenterCrop(CROP_SIZE)\n",
    "        self.random_transforms = [RandomRotation((90, 90)), RandomVerticalFlip(1.0), RandomHorizontalFlip(1.0),(lambda x: x)]\n",
    "        self.get_aug_transform = (lambda: random.sample(self.random_transforms, 1)[0])\n",
    "        self.load_patch = load_patch\n",
    "\n",
    "        print('Dataset ready with {} tuples.'.format(len(patches)))\n",
    "\n",
    "    @staticmethod\n",
    "    def random_temporal_order_swap(x1, x2):\n",
    "        if random.random() <= RANDOM_TEMPORAL_ORDER_SWAP_PROB:\n",
    "            return x2, x1\n",
    "        else:\n",
    "            return x1, x2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        frames = self.load_patch(self.patches[index])\n",
    "        aug_transform = self.get_aug_transform()\n",
    "        x1, target, x2 = (pil_to_tensor(self.crop(aug_transform(x))) for x in frames)\n",
    "        x1, x2, = self.random_temporal_order_swap(x1, x2)\n",
    "        input = torch.cat((x1, x2), dim=0)\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, tuples):\n",
    "        super(ValidationDataset, self).__init__()\n",
    "        self.tuples = tuples\n",
    "        self.crop = CenterCrop(CROP_SIZE)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        frames = self.tuples[index]\n",
    "        x1, target, x2 = (pil_to_tensor(self.crop(load_img(x))) for x in frames)\n",
    "        input = torch.cat((x1, x2), dim=0)\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set():\n",
    "    patches = prepare_dataset()\n",
    "    patches = patches[:MAX_TRAINING_SAMPLES]\n",
    "    return PatchDataset(patches)\n",
    "\n",
    "def get_validation_set():\n",
    "    davis_17_test = \"path to davis_17_test\"\n",
    "    tuples = tuples_from_davis(davis_17_test, res='480p')\n",
    "    n_samples = min(len(tuples), MAX_VALIDATION_SAMPLES)\n",
    "    random_ = random.Random(42)\n",
    "    tuples = random_.sample(tuples, n_samples)\n",
    "    return ValidationDataset(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
